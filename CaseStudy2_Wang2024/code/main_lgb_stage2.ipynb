{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import  StratifiedKFold,KFold\n",
    "from sklearn.metrics import roc_auc_score,f1_score,precision_score, recall_score\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        #print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        pass\n",
    "        #print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    ax.set_ylim(len(classes)-0.5, -0.5)\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    #plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "def cal(y,oof_lgb,p=0.5):\n",
    "    print(\"AUC score: {}\".format(roc_auc_score(y, oof_lgb)))\n",
    "    print(\"F1 score: {}\".format(f1_score(y, [1 if i >= p else 0 for i in oof_lgb])))\n",
    "    print(\"Precision score: {}\".format(precision_score(y, [1 if i >= p else 0 for i in oof_lgb])))\n",
    "    print(\"Recall score: {}\".format(recall_score(y, [1 if i >= p else 0 for i in oof_lgb])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ks_calc_cross(data,pred,y_label):\n",
    "    crossfreq = pd.crosstab(data[pred[0]],data[y_label[0]])\n",
    "    crossdens = crossfreq.cumsum(axis=0) / crossfreq.sum()\n",
    "    crossdens['gap'] = abs(crossdens[0] - crossdens[1])\n",
    "    ks = crossdens[crossdens['gap'] == crossdens['gap'].max()]\n",
    "    return ks,crossdens\n",
    "\n",
    "def ks_calc_auc(data,pred,y_label):\n",
    "    fpr,tpr,thresholds= roc_curve(data[y_label[0]],data[pred[0]])\n",
    "    ks = max(tpr-fpr)\n",
    "    return ks\n",
    "\n",
    "def ks_calc_2samp(data,pred,y_label):\n",
    "    Bad = data.loc[data[y_label[0]]==1,pred[0]]\n",
    "    Good = data.loc[data[y_label[0]]==0, pred[0]]\n",
    "    data1 = Bad.values\n",
    "    data2 = Good.values\n",
    "    n1 = data1.shape[0]\n",
    "    n2 = data2.shape[0]\n",
    "    data1 = np.sort(data1)\n",
    "    data2 = np.sort(data2)\n",
    "    data_all = np.concatenate([data1,data2])\n",
    "    cdf1 = np.searchsorted(data1,data_all,side='right')/(1.0*n1)\n",
    "    cdf2 = (np.searchsorted(data2,data_all,side='right'))/(1.0*n2)\n",
    "    ks = np.max(np.absolute(cdf1-cdf2))\n",
    "    cdf1_df = pd.DataFrame(cdf1)\n",
    "    cdf2_df = pd.DataFrame(cdf2)\n",
    "    cdf_df = pd.concat([cdf1_df,cdf2_df],axis = 1)\n",
    "    cdf_df.columns = ['cdf_Bad','cdf_Good']\n",
    "    cdf_df['gap'] = cdf_df['cdf_Bad']-cdf_df['cdf_Good']\n",
    "    return ks,cdf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "miss rate_training data\n",
      "TI       0.198646\n",
      "Y        0.169900\n",
      "NB       0.331628\n",
      "LA       0.082116\n",
      "CE       0.000000\n",
      "CE*      0.194634\n",
      "PR       0.152527\n",
      "ND       0.008613\n",
      "SM       0.017041\n",
      "EU       0.006956\n",
      "EU*      0.024219\n",
      "GD       0.023888\n",
      "TB       0.081048\n",
      "DY       0.005705\n",
      "HO       0.076374\n",
      "ER       0.022636\n",
      "TM       0.095992\n",
      "YB       0.033862\n",
      "LU       0.046156\n",
      "HF       0.161140\n",
      "TA       0.406088\n",
      "TH       0.118885\n",
      "U        0.113843\n",
      "label    0.000000\n",
      "dtype: float64\n",
      "####################\n",
      "miss rate_application data\n",
      "TI       0.154220\n",
      "Y        0.082300\n",
      "NB       0.216497\n",
      "LA       0.137399\n",
      "CE       0.001141\n",
      "CE*      0.365527\n",
      "PR       0.029777\n",
      "ND       0.010416\n",
      "SM       0.000626\n",
      "EU       0.001951\n",
      "EU*      0.006404\n",
      "GD       0.000221\n",
      "TB       0.040414\n",
      "DY       0.000074\n",
      "HO       0.020575\n",
      "ER       0.000478\n",
      "TM       0.104715\n",
      "YB       0.000000\n",
      "LU       0.000037\n",
      "HF       0.039972\n",
      "TA       0.391292\n",
      "TH       0.010674\n",
      "U        0.004932\n",
      "label    1.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "train_data_list = ['training_raw data_1.xlsx','training_raw data_0.xlsx']\n",
    "train_data = pd.DataFrame()\n",
    "for file in train_data_list:\n",
    "    _ = pd.read_excel('../data/{}'.format(file))\n",
    "    if '1' in file:\n",
    "        _['label'] = 1\n",
    "        label2 = _.iloc[:,0].values\n",
    "        _ = _.iloc[:,1:]\n",
    "    else:\n",
    "        _['label'] = 0\n",
    "        _ = _.iloc[:,1:]\n",
    "    _.columns = ['TI', 'Y', 'NB', 'LA', 'CE', 'CE*', 'PR', 'ND', 'SM', 'EU', 'EU*', 'GD', 'TB', 'DY',\n",
    "       'HO', 'ER', 'TM', 'YB', 'LU', 'HF', 'TA', 'TH', 'U', 'label']\n",
    "    train_data = pd.concat([train_data,_], axis=0)\n",
    "train_data = train_data.reset_index(drop=True) \n",
    "\n",
    "valid = pd.read_excel('../data/{}'.format('application data.xlsx'))\n",
    "valid['label']=np.nan\n",
    "\n",
    "print('#'*20)\n",
    "print('miss rate_training data')\n",
    "print(train_data.isnull().sum() / (valid.shape[0]))\n",
    "print('#'*20)\n",
    "print('miss rate_application data')\n",
    "print(valid.isnull().sum() / (valid.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label = pd.read_excel('../res/training data_label.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label_valid = pd.read_excel('../res/application data_label.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20923, 24), (20923, 123))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, df_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CE**EU*EU', 'YB/LU', 'NB/LA/CE*', 'TM/YB', 'Y/LA/TB', 'ER/YB', 'TH/U',\n",
       "       'EU**EU**TA', 'ER/TM', 'PR/ND/EU*',\n",
       "       ...\n",
       "       'NB/HF/TA', 'NB/TA', 'TB/DY/HF', 'NB-TA-TA', 'SM/GD/HF', 'EU/EU*/GD',\n",
       "       'CE/TH', 'label', 'prob', 'pred'],\n",
       "      dtype='object', length=123)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['pred'] = df_label['pred']\n",
    "train_data = train_data[(train_data['label']==1)]\n",
    "train_data['label2'] = label2\n",
    "\n",
    "train_data = train_data[(train_data['label']==1)&(train_data['pred']==1)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    1563\n",
       "2     263\n",
       "1     151\n",
       "Name: label2, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['label2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid['pred'] = df_label_valid['pred']\n",
    "valid = valid[(valid['pred']==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TI</th>\n",
       "      <th>Y</th>\n",
       "      <th>NB</th>\n",
       "      <th>LA</th>\n",
       "      <th>CE</th>\n",
       "      <th>CE*</th>\n",
       "      <th>PR</th>\n",
       "      <th>ND</th>\n",
       "      <th>SM</th>\n",
       "      <th>EU</th>\n",
       "      <th>...</th>\n",
       "      <th>TA*TA*U</th>\n",
       "      <th>TA/TA/U</th>\n",
       "      <th>TA+TH+TH</th>\n",
       "      <th>TA-TH-TH</th>\n",
       "      <th>TA*TH*TH</th>\n",
       "      <th>TA/TH/TH</th>\n",
       "      <th>TA+TH+U</th>\n",
       "      <th>TA-TH-U</th>\n",
       "      <th>TA*TH*U</th>\n",
       "      <th>TA/TH/U</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-99.000</td>\n",
       "      <td>-99.000</td>\n",
       "      <td>-99.000</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>1.720</td>\n",
       "      <td>13.658707</td>\n",
       "      <td>0.0615</td>\n",
       "      <td>0.951</td>\n",
       "      <td>1.560</td>\n",
       "      <td>0.647</td>\n",
       "      <td>...</td>\n",
       "      <td>1.507394e+06</td>\n",
       "      <td>0.006502</td>\n",
       "      <td>112.600</td>\n",
       "      <td>-310.600</td>\n",
       "      <td>-1.108170e+06</td>\n",
       "      <td>-0.008844</td>\n",
       "      <td>160.600</td>\n",
       "      <td>-358.600</td>\n",
       "      <td>-1.610932e+06</td>\n",
       "      <td>-0.006084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-99.000</td>\n",
       "      <td>-99.000</td>\n",
       "      <td>-99.000</td>\n",
       "      <td>0.0670</td>\n",
       "      <td>0.860</td>\n",
       "      <td>3.505490</td>\n",
       "      <td>0.0540</td>\n",
       "      <td>0.670</td>\n",
       "      <td>2.900</td>\n",
       "      <td>1.690</td>\n",
       "      <td>...</td>\n",
       "      <td>1.516215e+07</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>-79.940</td>\n",
       "      <td>-118.060</td>\n",
       "      <td>-8.991269e+03</td>\n",
       "      <td>-1.090057</td>\n",
       "      <td>1457.530</td>\n",
       "      <td>-1655.530</td>\n",
       "      <td>-1.459548e+06</td>\n",
       "      <td>-0.006715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>0.001</td>\n",
       "      <td>116.300</td>\n",
       "      <td>0.557</td>\n",
       "      <td>-99.0000</td>\n",
       "      <td>7.240</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.300</td>\n",
       "      <td>...</td>\n",
       "      <td>1.620105e+06</td>\n",
       "      <td>0.006050</td>\n",
       "      <td>124.600</td>\n",
       "      <td>-322.600</td>\n",
       "      <td>-1.237425e+06</td>\n",
       "      <td>-0.007920</td>\n",
       "      <td>178.100</td>\n",
       "      <td>-376.100</td>\n",
       "      <td>-1.829573e+06</td>\n",
       "      <td>-0.005357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>44.795</td>\n",
       "      <td>148.268</td>\n",
       "      <td>7.362</td>\n",
       "      <td>0.0290</td>\n",
       "      <td>3.143</td>\n",
       "      <td>16.523396</td>\n",
       "      <td>0.0750</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.302</td>\n",
       "      <td>...</td>\n",
       "      <td>7.651337e+02</td>\n",
       "      <td>0.004434</td>\n",
       "      <td>40.676</td>\n",
       "      <td>-36.992</td>\n",
       "      <td>6.944706e+02</td>\n",
       "      <td>0.004886</td>\n",
       "      <td>246.765</td>\n",
       "      <td>-243.081</td>\n",
       "      <td>8.065473e+03</td>\n",
       "      <td>0.000421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>7.234</td>\n",
       "      <td>3314.300</td>\n",
       "      <td>37.593</td>\n",
       "      <td>0.0650</td>\n",
       "      <td>20.243</td>\n",
       "      <td>18.881484</td>\n",
       "      <td>1.0630</td>\n",
       "      <td>12.721</td>\n",
       "      <td>23.589</td>\n",
       "      <td>1.146</td>\n",
       "      <td>...</td>\n",
       "      <td>7.204866e+03</td>\n",
       "      <td>0.003943</td>\n",
       "      <td>506.264</td>\n",
       "      <td>-495.604</td>\n",
       "      <td>3.343707e+05</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>509.410</td>\n",
       "      <td>-498.750</td>\n",
       "      <td>3.385706e+05</td>\n",
       "      <td>0.000084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27150</th>\n",
       "      <td>41.400</td>\n",
       "      <td>429.000</td>\n",
       "      <td>2.630</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>8.550</td>\n",
       "      <td>52.423551</td>\n",
       "      <td>0.1230</td>\n",
       "      <td>1.260</td>\n",
       "      <td>2.280</td>\n",
       "      <td>0.910</td>\n",
       "      <td>...</td>\n",
       "      <td>2.095040e+02</td>\n",
       "      <td>0.009625</td>\n",
       "      <td>224.820</td>\n",
       "      <td>-221.980</td>\n",
       "      <td>1.771718e+04</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>217.020</td>\n",
       "      <td>-214.180</td>\n",
       "      <td>1.647999e+04</td>\n",
       "      <td>0.000122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27156</th>\n",
       "      <td>20.500</td>\n",
       "      <td>2030.000</td>\n",
       "      <td>18.160</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>131.500</td>\n",
       "      <td>246.554113</td>\n",
       "      <td>0.2850</td>\n",
       "      <td>5.440</td>\n",
       "      <td>10.110</td>\n",
       "      <td>3.390</td>\n",
       "      <td>...</td>\n",
       "      <td>1.774108e+03</td>\n",
       "      <td>0.014205</td>\n",
       "      <td>240.420</td>\n",
       "      <td>-230.380</td>\n",
       "      <td>6.954352e+04</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>193.120</td>\n",
       "      <td>-183.080</td>\n",
       "      <td>4.159612e+04</td>\n",
       "      <td>0.000606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27157</th>\n",
       "      <td>86.800</td>\n",
       "      <td>551.000</td>\n",
       "      <td>3.450</td>\n",
       "      <td>0.0750</td>\n",
       "      <td>19.980</td>\n",
       "      <td>25.121492</td>\n",
       "      <td>0.5070</td>\n",
       "      <td>6.140</td>\n",
       "      <td>6.390</td>\n",
       "      <td>2.700</td>\n",
       "      <td>...</td>\n",
       "      <td>3.568738e+02</td>\n",
       "      <td>0.012240</td>\n",
       "      <td>346.090</td>\n",
       "      <td>-341.910</td>\n",
       "      <td>6.183056e+04</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>255.790</td>\n",
       "      <td>-251.610</td>\n",
       "      <td>2.936952e+04</td>\n",
       "      <td>0.000149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27158</th>\n",
       "      <td>20.000</td>\n",
       "      <td>2119.000</td>\n",
       "      <td>17.930</td>\n",
       "      <td>0.0490</td>\n",
       "      <td>178.300</td>\n",
       "      <td>313.826970</td>\n",
       "      <td>0.3960</td>\n",
       "      <td>6.220</td>\n",
       "      <td>10.350</td>\n",
       "      <td>3.780</td>\n",
       "      <td>...</td>\n",
       "      <td>3.359192e+03</td>\n",
       "      <td>0.007622</td>\n",
       "      <td>619.060</td>\n",
       "      <td>-608.940</td>\n",
       "      <td>4.768999e+05</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>443.260</td>\n",
       "      <td>-433.140</td>\n",
       "      <td>2.038087e+05</td>\n",
       "      <td>0.000126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27163</th>\n",
       "      <td>48.500</td>\n",
       "      <td>596.000</td>\n",
       "      <td>2.580</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>12.080</td>\n",
       "      <td>44.803379</td>\n",
       "      <td>0.1900</td>\n",
       "      <td>2.370</td>\n",
       "      <td>4.560</td>\n",
       "      <td>1.280</td>\n",
       "      <td>...</td>\n",
       "      <td>6.345806e+02</td>\n",
       "      <td>0.005163</td>\n",
       "      <td>512.010</td>\n",
       "      <td>-508.390</td>\n",
       "      <td>1.177876e+05</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>450.610</td>\n",
       "      <td>-446.990</td>\n",
       "      <td>8.943729e+04</td>\n",
       "      <td>0.000037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>727 rows × 10248 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           TI         Y      NB       LA       CE         CE*      PR      ND  \\\n",
       "23    -99.000   -99.000 -99.000   0.0155    1.720   13.658707  0.0615   0.951   \n",
       "24    -99.000   -99.000 -99.000   0.0670    0.860    3.505490  0.0540   0.670   \n",
       "416     0.001   116.300   0.557 -99.0000    7.240  -99.000000  0.0250   0.270   \n",
       "728    44.795   148.268   7.362   0.0290    3.143   16.523396  0.0750   0.646   \n",
       "729     7.234  3314.300  37.593   0.0650   20.243   18.881484  1.0630  12.721   \n",
       "...       ...       ...     ...      ...      ...         ...     ...     ...   \n",
       "27150  41.400   429.000   2.630   0.0130    8.550   52.423551  0.1230   1.260   \n",
       "27156  20.500  2030.000  18.160   0.0600  131.500  246.554113  0.2850   5.440   \n",
       "27157  86.800   551.000   3.450   0.0750   19.980   25.121492  0.5070   6.140   \n",
       "27158  20.000  2119.000  17.930   0.0490  178.300  313.826970  0.3960   6.220   \n",
       "27163  48.500   596.000   2.580   0.0230   12.080   44.803379  0.1900   2.370   \n",
       "\n",
       "           SM     EU  ...       TA*TA*U   TA/TA/U  TA+TH+TH  TA-TH-TH  \\\n",
       "23      1.560  0.647  ...  1.507394e+06  0.006502   112.600  -310.600   \n",
       "24      2.900  1.690  ...  1.516215e+07  0.000646   -79.940  -118.060   \n",
       "416     0.450  0.300  ...  1.620105e+06  0.006050   124.600  -322.600   \n",
       "728     0.750  0.302  ...  7.651337e+02  0.004434    40.676   -36.992   \n",
       "729    23.589  1.146  ...  7.204866e+03  0.003943   506.264  -495.604   \n",
       "...       ...    ...  ...           ...       ...       ...       ...   \n",
       "27150   2.280  0.910  ...  2.095040e+02  0.009625   224.820  -221.980   \n",
       "27156  10.110  3.390  ...  1.774108e+03  0.014205   240.420  -230.380   \n",
       "27157   6.390  2.700  ...  3.568738e+02  0.012240   346.090  -341.910   \n",
       "27158  10.350  3.780  ...  3.359192e+03  0.007622   619.060  -608.940   \n",
       "27163   4.560  1.280  ...  6.345806e+02  0.005163   512.010  -508.390   \n",
       "\n",
       "           TA*TH*TH  TA/TH/TH   TA+TH+U   TA-TH-U       TA*TH*U   TA/TH/U  \n",
       "23    -1.108170e+06 -0.008844   160.600  -358.600 -1.610932e+06 -0.006084  \n",
       "24    -8.991269e+03 -1.090057  1457.530 -1655.530 -1.459548e+06 -0.006715  \n",
       "416   -1.237425e+06 -0.007920   178.100  -376.100 -1.829573e+06 -0.005357  \n",
       "728    6.944706e+02  0.004886   246.765  -243.081  8.065473e+03  0.000421  \n",
       "729    3.343707e+05  0.000085   509.410  -498.750  3.385706e+05  0.000084  \n",
       "...             ...       ...       ...       ...           ...       ...  \n",
       "27150  1.771718e+04  0.000114   217.020  -214.180  1.647999e+04  0.000122  \n",
       "27156  6.954352e+04  0.000362   193.120  -183.080  4.159612e+04  0.000606  \n",
       "27157  6.183056e+04  0.000071   255.790  -251.610  2.936952e+04  0.000149  \n",
       "27158  4.768999e+05  0.000054   443.260  -433.140  2.038087e+05  0.000126  \n",
       "27163  1.177876e+05  0.000028   450.610  -446.990  8.943729e+04  0.000037  \n",
       "\n",
       "[727 rows x 10248 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3607: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._set_item(key, value)\n",
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1817: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    }
   ],
   "source": [
    "feas = ['TI', 'Y', 'NB', 'LA', 'CE', 'CE*', 'PR', 'ND', 'SM', 'EU', 'EU*', 'GD', 'TB', 'DY',\n",
    "       'HO', 'ER', 'TM', 'YB', 'LU', 'HF', 'TA', 'TH', 'U']\n",
    "for fea in feas:\n",
    "    train_data['{}_isnull'.format(fea)] = 0\n",
    "    valid['{}_isnull'.format(fea)] = 0\n",
    "    train_data.loc[train_data[fea].isnull(), '{}_isnull'.format(fea)] =1\n",
    "    valid.loc[valid[fea].isnull(), '{}_isnull'.format(fea)] =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.fillna(-99)\n",
    "valid = valid.fillna(-99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(train_data, test_size=0.3, random_state=42)\n",
    "#X_train.to_excel('../res/training_set.xlsx', index=True)\n",
    "#X_test.to_excel('../res/test_set.xlsx', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "feas_expode = []\n",
    "for i in range(len(feas)-1):\n",
    "    for j in range(i,len(feas)):\n",
    "        for data in [train_data,valid]:\n",
    "            data['{}+{}'.format(feas[i],feas[j])] = data[feas[i]]+data[feas[j]]\n",
    "            data['{}-{}'.format(feas[i],feas[j])] = data[feas[i]]-data[feas[j]]\n",
    "            data['{}*{}'.format(feas[i],feas[j])] = data[feas[i]]*data[feas[j]]\n",
    "            data['{}/{}'.format(feas[i],feas[j])] = data[feas[i]]/(data[feas[j]]+1e-10)\n",
    "#           data['{}^{}'.format(feas[i],feas[j])] = data[feas[i]]**(train_data[feas[j]]+1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51e08f8b06cb47e7a6a005678a4e19db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in tqdm(range(len(feas)-2)):\n",
    "    for j in range(i,len(feas)-1):\n",
    "        for k in range(j,len(feas)):\n",
    "            for data in [train_data,valid]:\n",
    "                data['{}+{}+{}'.format(feas[i],feas[j],feas[k])] = data[feas[i]]+data[feas[j]]+data[feas[k]]\n",
    "                data['{}-{}-{}'.format(feas[i],feas[j],feas[k])] = data[feas[i]]-data[feas[j]]-data[feas[k]]\n",
    "                data['{}*{}*{}'.format(feas[i],feas[j],feas[k])] = data[feas[i]]*data[feas[j]]*data[feas[k]]\n",
    "                data['{}/{}/{}'.format(feas[i],feas[j],feas[k])] = data[feas[i]]/(data[feas[j]]+1e-10)/(data[feas[k]]+1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(train_data, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'learning_rate': 0.01,\n",
    "    'min_child_samples': 5,\n",
    "#     'num_leaves': 63,\n",
    "    'max_depth': 7,\n",
    "    'lambda_l1': 0.5,\n",
    "    'boosting': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'n_estimators': 2000,\n",
    "    'metric': 'multi_error',\n",
    "    'num_class': 6,\n",
    "    'feature_fraction': .75,\n",
    "    'bagging_fraction': .85,\n",
    "    'seed': 1,\n",
    "    'is_unbalance':True,\n",
    "#     'num_threads': 20,\n",
    "#     'verbose': -1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score,confusion_matrix,classification_report\n",
    "eval_fun = f1_score\n",
    "def run_oof(clf, feas_all, feas_cat, X_train, y_train, X_test, kf):\n",
    "#     print(clf)\n",
    "    \n",
    "    model_lst = []\n",
    "    df_impt = pd.DataFrame()\n",
    "    preds_train = np.zeros((len(X_train), 3), dtype = np.float)\n",
    "    preds_test = np.zeros((len(X_test), 3), dtype = np.float)\n",
    "    train_loss = []; test_loss = []\n",
    "\n",
    "    i = 1\n",
    "    for train_index, test_index in kf.split(X_train, y_train):\n",
    "        x_tr = X_train[train_index]; x_te = X_train[test_index]\n",
    "        y_tr = y_train[train_index]; y_te = y_train[test_index]\n",
    "        model = clf.fit(x_tr, y_tr, eval_set = [(x_te, y_te)],\n",
    "                        categorical_feature=feas_cat,\n",
    "                        early_stopping_rounds = 500, verbose = 200)\n",
    "        \n",
    "        train_loss.append(eval_fun(y_tr, np.argmax(model.predict_proba(x_tr)[:], 1), average='macro'))\n",
    "        test_loss.append(eval_fun(y_te, np.argmax(model.predict_proba(x_te)[:], 1), average='macro'))\n",
    "\n",
    "        preds_train[test_index] = model.predict_proba(x_te)[:]\n",
    "        preds_test += model.predict_proba(X_test)[:]\n",
    "        \n",
    "        df_impt_ = pd.DataFrame()\n",
    "        df_impt_['fea'] = feas_all\n",
    "        df_impt_['impt'] = model.feature_importances_\n",
    "        df_impt_['fold'] = i\n",
    "        \n",
    "        df_impt = pd.concat([df_impt,df_impt_], axis=0)\n",
    "        \n",
    "        print('{0}: Train {1:0.7f} Val {2:0.7f}/{3:0.7f}'.format(i, train_loss[-1], test_loss[-1], np.mean(test_loss)))\n",
    "        print('-' * 50)\n",
    "        i += 1\n",
    "        model_lst.append(model)\n",
    "        \n",
    "    df_impt = df_impt.groupby(['fea'])['impt'].mean().reset_index()\n",
    "    print('Val_f1: ', test_loss)\n",
    "    print('Val_f1_mean: ', np.mean(test_loss))\n",
    "    print('Val_std: ', np.std(test_loss))\n",
    "    print('-' * 50)\n",
    "    preds_test /= n_fold\n",
    "    return preds_train, preds_test, df_impt, test_loss,model_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['label2']-1\n",
    "y_test = test['label2']-1\n",
    "cat_cols = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "D:\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1555: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is []\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.85, subsample=1.0 will be ignored. Current value: bagging_fraction=0.85\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[200]\tvalid_0's multi_error: 0.0180505\n",
      "[400]\tvalid_0's multi_error: 0.0144404\n",
      "[600]\tvalid_0's multi_error: 0.0144404\n",
      "Early stopping, best iteration is:\n",
      "[228]\tvalid_0's multi_error: 0.0144404\n",
      "1: Train 1.0000000 Val 0.9618820/0.9618820\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.85, subsample=1.0 will be ignored. Current value: bagging_fraction=0.85\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 500 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "D:\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1555: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is []\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's multi_error: 0.0541516\n",
      "[400]\tvalid_0's multi_error: 0.0541516\n",
      "[600]\tvalid_0's multi_error: 0.0541516\n",
      "Early stopping, best iteration is:\n",
      "[151]\tvalid_0's multi_error: 0.0505415\n",
      "2: Train 0.9978128 Val 0.8537790/0.9078305\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.85, subsample=1.0 will be ignored. Current value: bagging_fraction=0.85\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 500 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "D:\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1555: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is []\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's multi_error: 0.0505415\n",
      "[400]\tvalid_0's multi_error: 0.032491\n",
      "[600]\tvalid_0's multi_error: 0.0288809\n",
      "[800]\tvalid_0's multi_error: 0.0288809\n",
      "Early stopping, best iteration is:\n",
      "[477]\tvalid_0's multi_error: 0.0288809\n",
      "3: Train 1.0000000 Val 0.9351758/0.9169456\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.85, subsample=1.0 will be ignored. Current value: bagging_fraction=0.85\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 500 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "D:\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1555: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is []\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's multi_error: 0.0326087\n",
      "[400]\tvalid_0's multi_error: 0.0326087\n",
      "[600]\tvalid_0's multi_error: 0.0326087\n",
      "Early stopping, best iteration is:\n",
      "[267]\tvalid_0's multi_error: 0.0289855\n",
      "4: Train 1.0000000 Val 0.9303917/0.9203071\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.85, subsample=1.0 will be ignored. Current value: bagging_fraction=0.85\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 500 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "D:\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1555: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is []\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's multi_error: 0.0326087\n",
      "[400]\tvalid_0's multi_error: 0.0289855\n",
      "[600]\tvalid_0's multi_error: 0.0326087\n",
      "[800]\tvalid_0's multi_error: 0.0326087\n",
      "Early stopping, best iteration is:\n",
      "[399]\tvalid_0's multi_error: 0.0289855\n",
      "5: Train 1.0000000 Val 0.9327052/0.9227867\n",
      "--------------------------------------------------\n",
      "Val_f1:  [0.9618819776714513, 0.8537790460660416, 0.9351757817130123, 0.9303917285568661, 0.9327052045545526]\n",
      "Val_f1_mean:  0.9227867477123848\n",
      "Val_std:  0.03633235355796976\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cols_flt = ['CE**EU*EU', 'YB/LU', 'NB/LA/CE*', 'TM/YB', 'Y/LA/TB', 'ER/YB', 'TH/U', 'EU**EU**TA', 'ER/TM', 'PR/ND/EU*', 'LU/TH', 'HO-LU', 'TI*TI*CE', 'TB/DY', 'TH-U', 'DY/HO', 'TA/U', 'Y/CE*/TH', 'NB*EU**U', 'Y/CE*/EU', 'TI*TI*DY', 'Y/DY/HF', 'HF-U', 'ND-EU-EU', 'TI*EU**U', 'CE**ND*HF', 'NB/LU/TA', 'EU/GD', 'Y*HF*TA', 'Y/CE/EU*', 'Y/YB/TH', 'YB/LU/HF', 'CE-ND-TA', 'PR/ND/TA', 'SM/GD', 'TI/NB/EU*', 'GD/TB', 'CE/U', 'Y/NB', 'Y*EU**HF', 'TI*TI*U', 'HO/ER', 'LA+EU*+TA', 'CE/DY/U', 'CE/EU/TA', 'TI*TI*TA', 'TI/EU*/HF', 'TI*Y*TA', 'CE/HF/HF', 'CE/GD', 'TI*EU*HF', 'CE/HF/TH', 'CE/GD/HF', 'CE/EU*/TH', 'TI*Y*EU*', 'TI*HF*HF', 'EU**HF*TA', 'HF-TH-U', 'EU/GD/HF', 'YB/LU/TA', 'CE/EU*', 'NB/CE/CE', 'Y/CE/U', 'CE/DY/DY', 'Y/TH', 'PR/EU/TA', 'CE/EU*/EU*', 'EU**HF*HF', 'Y/TM', 'Y/HO', 'Y/NB/EU*', 'NB/HF/U', 'ER-LU-LU', 'HO-LU-TA', 'TI*NB*TA', 'Y/EU*/U', 'Y/ER', 'Y/NB/ER', 'TI/EU*/TA', 'HO/TM', 'CE/TA/TH', 'TM/YB/HF', 'TI*HF*TA', 'TB/LU/HF', 'ER/LU', 'Y/DY/TA', 'DY-LU-LU', 'CE/EU/TH', 'ER/TM/HF', 'TA*U', 'TM/LU', 'NB/HF/TH', 'CE*EU**HF', 'Y*CE*EU*', 'Y/NB/YB', 'ND-EU-EU*', 'NB/TH/U', 'CE/TA/U', 'Y/SM', 'TI/HF/HF', 'Y/YB', 'TI/HF', 'EU*/TA/TA', 'CE/EU/HF', 'DY-LU-TA', 'CE/SM/HF', 'DY/LU', 'ER/YB/HF', 'Y/DY', 'Y/NB/CE', 'SM/EU/TA', 'CE/EU/EU*', 'CE/EU*/U', 'NB/HF/TA', 'NB/TA', 'TB/DY/HF', 'NB-TA-TA', 'SM/GD/HF', 'EU/EU*/GD', 'CE/TH']\n",
    "y_train = y.values\n",
    "X_test = test[cols_flt].values\n",
    "\n",
    "n_fold = 5\n",
    "seed = 42\n",
    "skf = StratifiedKFold(n_splits = n_fold, shuffle = True, random_state=seed)\n",
    "train_pred, test_pred, df_impt, test_loss, model_lst = run_oof(lgb.LGBMClassifier(**params), \n",
    "                                cols_flt,\n",
    "                                [],\n",
    "                                X_train, \n",
    "                                y_train, \n",
    "                                X_test, \n",
    "                                skf,\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = valid[cols_flt].values\n",
    "preds_valid = np.zeros((len(X_valid), 3), dtype = np.float)\n",
    "for i in range(5):\n",
    "    preds_valid += model_lst[i].predict_proba(X_valid)[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# 绘制混淆矩阵\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    - cm : 计算出的混淆矩阵的值\n",
    "    - classes : 混淆矩阵中每一行每一列对应的列\n",
    "    - normalize : True:显示百分比, False:显示个数\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"显示百分比：\")\n",
    "        np.set_printoptions(formatter={'float': '{: 0.2f}'.format})\n",
    "        print(cm)\n",
    "    else:\n",
    "        print('显示具体数字：')\n",
    "        print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title ,fontsize=15)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45 ,fontsize=10)\n",
    "    plt.yticks(tick_marks, classes ,fontsize=10)\n",
    "    # matplotlib版本问题，如果不加下面这行代码，则绘制的混淆矩阵上下只能显示一半，有的版本的matplotlib不需要下面的代码，分别试一下即可\n",
    "    plt.ylim(len(classes) - 0.5, -0.5)\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\" ,fontsize=15)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label',fontsize=15)\n",
    "    plt.xlabel('Predicted label',fontsize=15)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "train-f1: 0.9247995277215862\n",
      "train-混淆矩阵\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.74      0.80       105\n",
      "           1       0.99      0.99      0.99       189\n",
      "           2       0.97      0.99      0.98      1089\n",
      "\n",
      "    accuracy                           0.97      1383\n",
      "   macro avg       0.95      0.91      0.92      1383\n",
      "weighted avg       0.97      0.97      0.97      1383\n",
      "\n",
      "####################\n",
      "test-f1: 0.9304484756865709\n",
      "test-混淆矩阵\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.72      0.81        46\n",
      "           1       1.00      0.99      0.99        74\n",
      "           2       0.97      1.00      0.98       474\n",
      "\n",
      "    accuracy                           0.97       594\n",
      "   macro avg       0.97      0.90      0.93       594\n",
      "weighted avg       0.97      0.97      0.97       594\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('#'*20)\n",
    "print('train-f1:', eval_fun(y_train, np.argmax(train_pred, 1), average='macro'))\n",
    "print('train-混淆矩阵')\n",
    "print(classification_report(y_train, np.argmax(train_pred, 1)) )\n",
    "print('#'*20)\n",
    "print('test-f1:', eval_fun(y_test, np.argmax(test_pred, 1), average='macro'))\n",
    "print('test-混淆矩阵')\n",
    "print(classification_report(y_test, np.argmax(test_pred, 1)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "train-混淆矩阵\n",
      "显示百分比：\n",
      "[[ 0.74  0.00  0.26]\n",
      " [ 0.00  0.99  0.01]\n",
      " [ 0.01  0.00  0.99]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "test-混淆矩阵\n",
      "显示百分比：\n",
      "[[ 0.72  0.00  0.28]\n",
      " [ 0.00  0.99  0.01]\n",
      " [ 0.00  0.00  1.00]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUoAAAEuCAYAAADoTFtJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3dd3wVVfrH8c+ThBZ6S5AAgmIBEamKFAXXuvay9oYixbo/K7i69op9QYpiB0FXEF27YgOxUG1goWkSqtJCDzm/P2YCN5fk3hvMvXeSfN+85jXMzJmZMyeTJ+ecaeacQ0RESpaS7AyIiASdAqWISBQKlCIiUShQiohEoUApIhKFAqWISBSVNlCa2d/NbJGZOTP708z2Dll2hJnNMbPnzGzPZOazkJk1MbNP/Pze7s/rY2ZrzGxwGe7nNDPb4u+nZVlttxT7P9g/zlFm9puZ9drN7ZR52cSbmXWJMd0IM1thZm3inSfxVNpA6Zx7G7gbcEB9YJKZ1fSXTQFGA/c655YkL5c7OeeWAZ+Gzd4TqAvsX4b7mQgsK6vtlYaZpQL/A1oCQ4HpwJbd3FyZl008mVkz4KkYk7cBGgOZ8cuRhKq0gdK3Hbjd//+BwDMhyzYCWxOdoSiKPB3gnHsO6AgMiOd+EigLLwDgnPvVOXeWc+7r3dlQHMumzJlZA+B1vD/YsTgJOMA590ncMiVFVPZACfAC8KD//zPN7KbiEpnZKWb2tZk9bGbTzKy3P38vM5vvN1X7mtkjZrbab77f4M/PNrNbzWy2mS03szPNbLCZfWlmy8zsuJD9nGBmj5vZMH9ZsU1HM6tnZq8Cs4FR/rwpfrPs/8xspr/vWf6yVDO7w8yGmtlEM7srZFttzWy6mc0ysxFA1UgFZmYZZvZfM3vCzJaY2fUxlFMzM/vRz9MIMxtvZnn+/jCzDOBZfzMZfrdHdX8/zp9u7G8ztPuhsZm97zfVc8xsZHFl46cdYGZfmNl/zOxjM2vvz2/j/1ycmT1oZm+a2Xozu7mE4z/Ab/o6M7vPz+NGM3vB/7mPM7MNZjYyZJ2m/s/032b2s5m95efdgIeBzkCmmb1rZueb2c3+9heb2UH+OfaumXUCfgF+MLPeZtbazGb4aRf6P8uvzeweM4s18Eo0zrlKOwAX4zXzUvD+ojsgHzi6cJmfri2wDXjIn34er8a5V8i0Az4DbgZWAH2Avfz5ef7/O/vT64H98Go8Dpjqb6elv/+7/ekv/eVt/enb/enb/em+/vRz/vQ1/nhvYLO/rIc/7068JnUK0MFfdjaQCvwMbABq+3nI85e3LKHcPg7J80d+2qwYyukFP+1wf3quP71/yPE7YHHIvsKP8c6wMrgHWInXDN0TGFrCekf701f6058Cy4F6/vRn/vIb/DL50/9Z1CyhDArT3+hPf+tP/yvs2FqHlNNCvD9CA/1lD0Y47lb+vJXAo8Bk4IOQvDugtz+9D17rJx/oDtyW7N+tijaoRgk45wqA8/FO9lTgZbzAVuhyIA0o7K/8HagBXFC4CX/8rXPuXudchnPuY6DAn7/KObcQ+MOf/sM59xOw2p9u4o83AN8Aa82slr8PgEYlZT1s+gl//BhQDRjrnJvmz7vGP7YbgVPxfnEbAN3wftF+cs6td84tBlaVsD/MrAPQm51lcQNwLZBL9HIqLI9v/HHh8Zd0fMUdY0Ex043wao/7AQ+VsN7V/jg0bxnAyeF5c85tB9bhlVdJtbLC9IVdA3/648LyDv/ZzgQW+dts7M+L5bgb4fWVn+ycOypsmTfh3C94feqpwGvAIxG2K7tBgdLnnMsDTsSrDTYAhoQsbuWPCy8sFP6SNAvbzLzd3H2an4eVwOF4P5fHQ/YT08/JOef8ZvwJeLXCG2FHs7YOXu3ofufcbc65I51zTwIt/NU3x5jXff1xhr/PWc65R51XtYm1nMKlxbjv4jyKFyT3AN7F+yNQnGTkbcf6zrkb8S4ejgOa+8ti+bmu8s+LaO7G+0PbBDhgN/IpEShQhnDO/QacgvfLFPoLUlgLqRo2/i1sExv+yv7NrAbwOXAm0B9YW8r1q+LVJgHucc7lmllTvNrNdqCGmXULSd8C7w8DeH8cYpHrj7ubWcOwZbGWU2nkR1leH6+5+R/AgPtKSBePvMXMzK4DpgB3AF+ELY508SzWc2ozXhcKeN0TUoYqe6Cszs7mLQDOuenAZWHpRuLVQAprJc3xTszn/emSytGijFPCpo8BDgZq4vWpFd7DmW7erTPRtvdPvBrfr8Aj/oWCa51z24D/+mmeNLNOZnYhXm1qKl7f5T5mtq+ZdWbnbSe1izmm6cCPQDowzsy6+hdJWhO9nKLlP3wMXj8iQG0zSwG6hqU5F2jvnLsar9m5Kmx54Xi4Pw7N2wpgUinyEqq0P9tb/XEnvFYDQJqZpePV/gGqm1kVMzuAyL+bxeXtJryr4WuBo8ysT4T1pbSS3UmarAE4Cq/J9grQsZjl9xFyMQOvlvcN3hXKGcCR/vwWeE1uh9esahSyzmB//lagB15/nsOrsR6G17x3eMHkELxf3gV4tbZrgFvwfomexQua0/z0H+M1NSf60z/666/zp98E7ge+Aqb4eWmEFxQ24tWiLgjJZw9gvr/fO/H60z4A/llC2bUC3se7KPUjcGIM5bSnvw/n57sz3oUKh1cLrh5WXqf466XhBfm1wHPAWD/NJ3i1ydv9fDyDd/GrM1AvrGz28bd1FV5tbpg/7ujPb48XkB1ezfRwPw+uuDIISz8cr6m7ImT6oNBj89d5Bq92OB44wk8/l50X6h7yfzav4d3/eaO//gbgqJB9dwnZ9jC88+8p/5xoC8zyl/0MtEv271lFGcwvfBERKUFlb3qLiESlQCkiEoUCpYhIFAqUIiJRKFCKiETxV586KHNp6XVdlbp6e9TuaNu0TrKzUG6t3xLtvnaJ5Jcf5q5yzjWOnjJ2qXX2dC5/U8zp3aaV7znnji3LPBQKXKCsUjeTlhf/J9nZKJem3XVMsrNQbk39pcTH2yUGR7VtXObvbXX5m6i235kxp988Z3ikZ+f/ksAFShERAMwgJTXZuQAUKEUkyCwYl1EUKEUkuKykR+0TS4FSRALKVKMUEYlKNUoRkQgM1ShFRCIz1ShFRKJSjVJEJArVKEVEItFVbxGRyAzVKEVEolKNUkQkEjW9RUQiMyBVL8UQEYlMfZQiIpGo6S0iEp1qlCIiUahGKSISgelZbxGR6FSjFBGJQjVKEZFIdNVbRCQ61ShFRCLQG85FRKJR01tEJDo1vUVEokjRSzFEREpmanoHRnrVVG47pS1/5G1l74yajJiykDm/rdkl3cuDDqFDi3pF5hUUOHrf/ykr12/hzIOb0b/3XtRLr8KUeSu44/Uf2bBle6IOI2nWr1/P1VcMIiMzk5/mz+OmIbdwaPfuu6Tbtm0bN15/Lc45fluymEv69eeEE0/asfzNNybz8riXqFO7DjVr1eKBoQ+TllaxT8+NG/J44o4bqNewMb8t/JnzBl7LAR0P3iXdiqU5/OeuG5nz1VQaZjThsutuo8eRfwegoKCAl0c/xg+zv+bAzt348pP3OfncSznihNMTfTjxEZCmdzDCdRLde0Y7surX4MG3f+KbRat5+pLOZNSpViRN1bQU2jatQ/72AtZs3MrqDVvZtHU7s5asYeX6LRzdLpMLuu/Jmo1bqVktjRM7NGXw8fsn6YgSq3+/vixZspgHhj5Mj16HcdLxx5CTk7NLulv/NYQ3Jk/isSeGcfa553POmacza+ZMAObOmcO5Z51Bv8sGMHzkaJ5/dgxDbroh0YeScA/96yqW5f7GwJvupH2XQxly2ZmsWr60SJqCggLuvrYfmzdtJK1KFXKWLOSe6y5j6e+LAXjtuRE898R9nHDWxZzT/590PPQwHhh8OQt/+iEJR1T2zCzmIZ4qdaDMrFONow7I5I+8rQCsWr+FmtXSOKNLsyLp2jery+2v/0DHf3/IoXd9TPe7P+abRX/y3vfLAEhLNU58bBpnDPuSsdN/A6BLq/qJPZgkyM7OZvKkiWRkZgLQJLMJeXl5PP/smCLptm7dytOjR5KZ4adr0oT8/HxGjRgOwKgRw8nPzycjI5PU1FQaNmrEmKdGsWXLlsQeUAKtXJbL1A/eon7DxgDUb5TBpo0beOe1sUXSLfr5R66981GGPjuJEa9NoXqNdLZt28q8ud4fmTlfTwXg1x+/BaBh40wKCgpY+vuSBB5NfHifzFGgTLrOLeuTkmJs214QNr9oE3vWktVMmplLfoEDoE71NA7ZqwHvf78cgLfnLtuR9rOfVgLw6/K8eGY9EL6YNhXnHFWrVi0yf9rUz4tMz541iw0bNlAlPN20z4uMQ7ezadMmZs6YEY9sB8L3s77COUdalaJl8v3ML4tM771/O1ru47VOmmS1YM/W+wHsGLc5qAsA40Y/ygeTJ/DTd7PZ/8BOdO11RLwPIf6slEMcVexOoCgy61YHYLsfAAtl1KleZDpsMX87IIPvc9axYt2uNZ5m9WsA8MK08v8XPZqcnGwAUsOuTC5dmlt8urDX+i/N9dLlZJewPGw7FcmqZd6xhZfdHyuWFZcc8Jrhy3Oz6XBIT/bevx0A51x2DdmLF/DRm6/y4JArqdegEcNf/ZCq1aqXuJ3yI/41xVhV6hplWsru/RCOPbAJ735X/Al9aucsxny6iG8Wrf4rWSsX8rdtiyndtijpoi2viPLzS3/MX336Aa6ggOvvfmLHPEtJoXmr1nTrcwz1GzZmzZ+ruP7iU1i7+o+yzG7SVLqmt5l1M7PJZnZS9NSJsXzdZmDXC2uF84sT3uwOddbBzfj9z408/N7PZZrPoMrK8vpynSta5W7aNKtoumYlpMvKirw8bDsVSaMmTYFdj7lh5h7Fpt+0IY/n/3M/dz05lsys5jvmj3n0bp574j4G3ngnj497mzr1GrD098W8Of65uOU9kSpVoDSzusA+wEmJ2mcsZi72bgOqlpYaNn81ezWuyd/bNyE1rNZ55AGZxTa799+jNp1a1ufGCd/hHOzVuCYdWtSN7wEkWfcePQHYvKXoH5YePXsxf948Xpkwnvz8fDp16kx6ejpbNoel69GryHhzyPL09HQ6de4cz+wnVbtOhwCwdWvRMjmwczeWLPiZj9+exPb8/B3zRz74by6/+R7aHNQZ5xzvTXoZgK8//QCAxntksUfzlpx87qUA5K1bm4jDiLugBMqE9FE659aa2efRUyZWzupNvPfdMprU8/pz6taowoYt+UyamcurV3SjUe1q1J70AxO+zt6xzrHtm/BeWLO7XnoVnji/AzWrpjFl8OGYP6/3/Z8m8nASrmWrVpxy2ulk//47AKtXr6ZmzZqcf+HF9OzWhRUrVrB2zRouGzCQywYMYvy4l3akS01NpV//gQBccdU1jH95LDk52RzQrh3r1q7lor6XUq1atRL3Xd7t0WxPeh19Aiv9fti8dWupXiOdo085myvOPIo1f6wk799DOfHsi/nvcyP48I1XmT7lXQC2bNnMEcefzjGnnsP+B3Vm8a/zyVm8gFb7tqVq9eqkpKZy2DEnJvPwykYCLtLEqlJfzAG45bUfuOPUttx2chtaNEyn79MzWLZ2M18v/JNDWzdk3tL1O9LWrVGFQ/ZqwK2vfb9jXorBE+d1oHmD9CLbXb52847bjiqykaPHcOXlA7j6ikEsWPAr77w/hebNm3NY7z58/NGHHNShIwB33n0vmzZupP+lfVm6NJdXJ06mS9euAHTo2JEXx01g1IjhjB83lvMuuIj7HhiazMNKiOvuepzHbr+Ox++4gdzfFjH02Ulk7JFFh4N7MGv6Z7RucyAzpn3MUw/fQcH27WwNqbnv07Y9AIMG301qSioj7r+V9l278/2sL7lr+Eu07dA1WYdVZixAF3MsvI8kbjsyawksAk51zr0etqw/0B8grU5G59aXv5CQPFU0s+86JtlZKLem/rIq2Vko145q23imc65LWW4zreFervZxd8Wcfs3Y88s8DzvyEo+NlpZzbjQwGqDGHvsmJnKLSOClpATjkkaiLuakA8f7k73MrHYi9isi5Vhlu+HcObcRGO4PIiIxCUofZSCa3iIi4cryYo6ZNQOuAeoBVznnNpvZ8UAnoBnwpHNubknrB6MDQESkGGV4H+UgYAFQBTjPnzcAcMB3QM9IK6tGKSLBVXYt7/3w7roBaOOPJwAvANOAv0daWTVKEQkmK3WNspGZzQgZ+odsLfQ1TaFxbyJebbJXpKyoRikigVXKPspVEe6j/J6dwXKJmTUBrgfOBjbj1TLfKWnDCpQiElhleNV7GHA1sA1oD6wDXgRO9///cqSVFShFJJDK8qq3cy4XGLy76ytQikhwBeM2SgVKEQko0w3nIiJRKVCKiERhu/m5lrKmQCkigaUapYhIBIn4xEOsFChFJLAUKEVEolCgFBGJJhhxUoFSRIJLNUoRkUh0w7mISGQGBCROKlCKSFDp9iARkagCEicVKEUkuFSjFBGJxFSjFBGJyIDU1GBESgVKEQksNb1FRCJR01tEJDLvPspgREoFShEJKN1HKSISVUDipAKliASXapQiIpHoYo6ISGS6mCMiEoOAxEkFShEJLtUoRUSiCEicDF6gbNu0DtPuOibZ2SiX6h9yTbKzUG6tmv5YsrMg4fSGcxGRyAwjJUWBUkQkooBUKBUoRSS41PQWEYlEN5yLiESmG85FRGKgQCkiEkVA4iQpf2VlMzutrDIiIhLOzGIe4qnEGqWZbY2yrvmDaqUiUvbKycWcWAKgK6uMiIiEsgC94TxS0/sCoCpQpYShKjAg3hkUkcrLLPYhnkqsNTrnxhbNsHUGmjrn3jSzZkCqc+7p+GZPRCqzlHJQo9zBzPoDXwNXATjnsoFTzexvccybiFRyZVWjNLNmZjbUzJ4ys+oh8/9mZv80sz0jrR/rVe/TgDOB2SHzPgCeiHF9EZFSMYPUFIt5iGIQsACv2/A8b/t2CHAj8LhzbkmklWMNlNOdc68Bf/g7aAI8CLSKcX0RkVIrw9uD9gPy/f+38cc3AcuAp8wsI9LKsQbKDDObBlxsZnOBRcCxwJcxri8iUmqlbHo3MrMZIUP/kE1VDfl/YdxrA7wE1ACujZSPWO+BvAF4Gjg0ZN4MoF+M64uIlIp3o3apLuascs51KWHZ9+wMlkv8VvFCoCHwOztrm8WKqUbpnNvonDsXyAR6APs65w52zi2MZX0Rkd2RYrEPUQwDWgDbgPbAccA9QB+8GuWISCvH/FSNmbUAjgdqAT+Y2SLn3PZY1xcRKZUyfDTROZcLDC5m0RexrB9ToDSzU4FxFG3n/2BmxznncmLZhohIaQXkNsqYa5QPA+uAr4A8IB04AK+6elJ8siYilZkRnBvOYw2UeUAb59yW0Jlm9nzZZ0lExBOQOBnz7UEvAFmhM8ysLpBa5jkSEfGVx9es3W9mBSHTqcD1ccmViFR6iXjZRawi1SjTwoaUsGnDfxRIRCQeUsxiHuIpUh/l2cBrcd27iEgEAalQRnzN2iuRVvTfwNEBPcYoInFgEMvLLhIi1vsoWwJ3A43Y2VxPA5oD+8QjYyJSySXgIk2sYr096HmgVzHzI76aSETkrwhInIw5UNYFTgQa4z0n+RZwNPB6nPKVMOvXr+fqKwaRkZnJT/PncdOQWzi0e/dd0m3bto0br78W5xy/LVnMJf36c8KJO++1f/ONybw87iXq1K5DzVq1eGDow6SlVfzvrtVKr8YTQ85kxZ/r2a9lJg+MeY8vv128S7pWzRry8A2n8+OvS+nVuTUv/e9rnvrvtB3LrzzncHp22pu8jVuoVyed/3vgv/y+bHUCjyTx1q9fzz+vupyMjAx+mj+fG4f8i26HFn/uDb6h8NxbQt9LL+P4E4s+5/HJx1MY9vijnHTKqVx48SWJOoS4C0qNMtb7KF8FpgFv4zW3q+G9m/LmOOUrYfr368uSJYt5YOjD9Oh1GCcdfww5Obs+lXnrv4bwxuRJPPbEMM4+93zOOfN0Zs2cCcDcOXM496wz6HfZAIaPHM3zz45hyE03JPpQkmL0beeyZ9MGDH70dabNXsAbwwbRtHHdImmqVknlreGXs+ceDbjlP2/yynuzeGLImfQ91XsZVd9TD2Xo9afxynuzGHDnyxx8YEveHnEF1atVScYhJczAyy7htyWLue/Bh+nRqxennHAsucWce7fdMoQ333idRx4fxlnnnsd5Z5/B7FneuffT/PkMvuFaTjzuKN595y0KCgp2Wb+88p7MKbOXYvwlsQbKRsCvwETgPmCyP+4Tp3wlRHZ2NpMnTSQjMxOAJplNyMvL4/lnxxRJt3XrVp4ePZLMDD9dkybk5+czasRwAEaNGE5+fj4ZGZmkpqbSsFEjxjw1ii1btlCRZWXU5eQj2rPij/UALPtjHbVrVueiU7oVSXd4l31o1awR6/I2A/D1d4sBuOHiIwG4+GQv/dq8TWzfXsCsH3+jdYvGnHZkhwQdSeLlZGfzxusTaeyfU5mF595zu557Y54aRUZIuvz8fEaP9M69/fbfn/uHPsLBhxQt84oiKDecxxoob8drbk90zs0CLgJ+BB6NU74S4otpU3HOUbVq1SLzp039vMj07Fmz2LBhA1XC0037vMg4dDubNm1i5owZ8ch2YHTvsBcpKSls3Vb0VX49OuxdZLqwZti4QS0A/lizAYBWzRpRv0461ap6XRSN69cG4M+1GwHo3LZ5/DKfZF98Ufy598XUqUWm58z2zr1o6cLPzYrCSjHEU6zvo1zrnLvIOfeIPz3OOXcg5fybOTk52QCkphR9EnPp0tzi06WGpcv10uVkl7A8bDsVTVZmPQC2FxT9vPsejesUmf7q28Wsy9vM3s0b03H/ZtSssfOXentBAR9Onw+wowaZXt0LrNu3V9zPxufGeM6UeO5V8HMLvAs5gb/h3Myi9T8acDjeRZ1yKX/btpjSbYuSLtryiiotLbZH/Vf8uZ7T/jmaWwcex9N3ns/K1XkA5K5Yw7q8zdw9+l3S0lI5unsbXnusP907eJ9imrdoWdzynmzb8svm3KvoAnItJ+JV77uB0D/pFmW63MnKagaAc0UPo2nTrKLpmpWQLitrx/JFCxdG3U5Fk7N8DbDryZy7cu0uaafNXsCxA4YB8OhNZ3B4l30Y97bXNbF5yzYGP/o6gx99nYwGtVn47p1s2ryVSR/Oie8BJFHM516M6SqqoFz1jhQopwKfUXIwNCDqd739twxNBDrifRbyjtJmMl669+gJwOYtm4vM79GzF/PnzePbb+dy2uln0KlTZ9LT09myOSxdj147xosWLmRzyPL09HQ6de4c5yNIri/meF8CqV616NXpabMXsF/LTNrv25SJH81l+/adV2L3aFSH847vyuKcP3jo2Q932ea1F/2N1NQUbn30f6xZvym+B5BEh3b3z72wc6p7z57MnzeP776by6mnnUFH/9wrLl1lEJA4GTFQnumci9j2MbOI35nwHQ88AgwAbjezp4PyVvSWrVpxymmnk/377wCsXr2amjVrcv6FF9OzWxdWrFjB2jVruGzAQC4bMIjx417akS41NZV+/QcCcMVV1zD+5bHk5GRzQLt2rFu7lov6Xkq1atWSdmyJsCT3TyZ9OIdmTby+yvq108nbuIWX3vyaqS9eT2bD2tS99xWefs27X7JRvZpMePhSfl+2mnNufIa1eUUD4QUnHsLlZx/G3aPeYfjLnyb8eBKpZatWnHzq6eRke+femsJz74KL6dW9Kyv9c69f/4H06z+Q8S+P9dKt8c69Sy8bWGR72/O9C2r5+RG/kVWuGPHve4xVpGe9o3YQxRLwnHPjAPxXtB2F96b0wBg5egxXXj6Aq68YxIIFv/LO+1No3rw5h/Xuw8cffchBHToCcOfd97Jp40b6X9qXpUtzeXXiZLp07QpAh44deXHcBEaNGM74cWM574KLuO+Bock8rIQZeNfLDLv5LB4f8g/2btaY4wYOI3v5Gj6b8Qt9DtmXuT9lk9GgNicc3o6ju7fh+clfMfatb9i8ZWff22FdWnNyn/ZUSUuj5wUP8+3Pgfg7GndPjnqaq68YyDVXDmLhggW89d5HNGvenMMO78PHU3aee7ffdS8bN25k4GWXsDQ3lwn/fZ3OXbxzb9nSpXzy8Ud8O9frpnj1lfHst38beh12eNKOq8wE6DVrFt73EbcdmQ0BajrnbilmWX+gP0DzFi06/7xAT0bujvqHXJPsLJRbq6Y/luwslGu1qqXMjPCp2N2S0bqdO2voqzGnH3Za2zLPQ6FY76P8S8ysId7LM24rbrlzbrRzrotzrkvjRo0TkSURCTij/N1wjplV8z9Zi5nVNbOY1jXvCB4DpgN9zeyU3cqpiFQ65eoRRjPrAfwGPO3PygduLQycUdwKnA+MBp4CKv6dsiJSJspVoMR7rvsVYBGAc24DMAF4LtqKzrk7nXMWMny9u5kVkcrD+2ZO+Wp6v+WcuwpYEDLvfKBiPokvIoEQlBplrC9M7GBm9wAHmVkW0BtoB8yPV8ZERIJye1CsgXII8AEQ+lqYTcD/lXmOREQofB9lMCJlTIHSObfYzNoBJ+MFy5XAZOfcynhmTkQqt4TcvxiDmL9V4JzbgndBZwczaxLLEzwiIrsjIBXKmL/COLq42UBXvE/WioiUKUvAeyZjFWuNsl8J88v1a9ZEJNgCEidjDpRvAv8DQr9c1A2o3G8VFZG4ivdtP7GKNVCe45zbGDZvjJmNK+sMiYiA17eXGpBIGWugfL2YO99rAweUbXZERHwJuJE8VrEGyiNLmB/Li3tFRHaLxf37irGJNVCOAl5j58WbfGC5c05P5ohIXHg3nCc7F55YA+VDQIFzblE8MyMiEqq8BcrpeLXJzDjmRUSkiPLwFcZQHwE/h880s2r+EzsiImUqSE3vWB+lfBpob2ZXm9lRZtbdzLoDd8UxbyJSmVnhOyljGyJuyqyZmQ01s6fMrHrYstfMrHWk9WOtUX6A1/Q+qZhlN8a4DRGRUinDRxgH4b1PtxtwHjAGwMx6A6cBN0VaOdZAuRqYR9FHFlOAfUuXVxGR2JRx03s//C80AG0AzKw2UC+WlWMNlH9zzriYliUAABIGSURBVM0Jn+m/ek1EJC5KWaFsZGYzQqZHO+cKX+hTNWR+YZfjacCLsWy4xEBpZlf7/53jnPusuDTOue9j2YmISOkZKaW74XxVhO96f8/OYLnEzJoA1+G9lBxgIHB9SRuOdDFnKLCkpCApIhJP3ne9y+ZiDjAMaIH3Ip/2wHHOufbOuf395SMjrRyp6T3OOTc54oGYtXbO/Ro1iyIipWWQVkadlM65XGBwCcui7iRSoNxuZs2hxLpvClGqqyIiu6uwRhkEkQLlJUDfGLahQCkicVFe3nAeLZd6w7mIxE1A4mTEQPkaXgdoSVLwap0iImXOKB9fYdzgnPs00spm9kcZ50dExGPBeSlGpIB9qpl1i7Syc+7bMs6PiMgOVoohniLVKB8BjjazGs65j+OcDxGRIrxHGINRoywxUDrn7khkRkREwgUjTMb+rLeISMIFpEKpQCkiQWWBuZijQCkigVRebg8SEUkq1ShFRKIIRpgMYKB0gHN6MnJ3rP7q8WRnodyq3/XKZGdBwphBqmqUIiKRqektIhJFMMKkAqWIBFhAKpQKlCISTN7tQcGIlAqUIhJYqlGKiERkmGqUIiKRqUYpIhKB+ihFRKKJ7XvdCaFAKSKBpUApIhKFLuaIiETgfQoi2bnwKFCKSGAF/ps5IiLJpqa3iEgEanqLiESlJ3NERCLTfZQiItEFJE4qUIpIMHl9lMEIlQqUIhJYwQiTCpQiEmQBiZQKlCISWLrqLSISRUC6KBUoRSS4AhInFShFJMACEikVKEUkkMx0e5CISFTBCJOQkuwMiIiUyEoxRNqMWTMzG2pmT5lZdX/eEWa2wszeNrOqkdav9DXK9evXc82Vl5ORmcH8+fMZPORfdDu0+y7ptm3bxk03XItzjiVLlnDJpZdxwokn7Vj+5huTGT9uLLXr1KZWrVrc/+DDpKVV/OJdv349V18xiIzMTH6aP4+bhtzCod2LL78br/fK77cli7mkX/9dyu/lcS9Rp3YdataqxQNDK0f5Nahbk35n9OSkPu3pef7QEtPd1O8YWmY1pGHdmrz9+fc8N2n6jmWHHrQX11xwBDkr1tCgbk2uumc8eRu3JCL7cVamL8UYBCwAugHnAWOAjcDBwC9AR+Crklau+GdiFAP6XcLy5ct45vkXeejB+znp+GOZ/d08srKyiqT79y1DeGPy6/y66HdenTCec886g0+mTqdTp87MnTOH887+B6+/+TaH9+5Dk0b1SElJ4cGHHk3SUSVO/359Wb5sGc++8BJDH7yfk44/hjnfz9+l/G791xDemDyJBYuzeWXCeM4583Q+nfolnTp75XfuWWcw+X/vcHjvPmQ2rEtKSgpDH67Y5XfBSd24+vwjaLdPU3KWry4x3cCzDuNf/f9O457XcdB+zfj0hetZtTqP/33yHZkNazN5+OXc+PBrPDdpOnMm3sKYuy7krOueSuCRxE8ZdlHuByzy/98GwDn3pZkZsBz4OdLKlbrpnZ2dzeTXJ5KRkQlAZpMm5OXl8fyzY4qk27p1K0+PHlUkXX5+PqNGDAdg1Mjh5Ofnk5GRSWpqKg0bNWLMU6PZsqUi/FUvWXZ2NpMnTSQj0yuXJpmRym8kmX75NQkvvxHFld+oCl9+L77xJYMfmRg13RXn9mbdhs1s2ZrPslXrvHnn9AbgolO6U7tmdVb8sR6A5X+s56QjDqJ5k/pxy3eilKbV7cfTRmY2I2ToH7K50KZ1aNw7FrjHOVfyXyoqeaCcPm0qzjmqVi3aPfHFtKlFpufMnsWGDRtKTPfFVG8cunzTpk3MmjkjHtkOjC9KKL9pUz8vMj17lld+VcLTTfu8yDi8/GbOqNjlB7B12/aIyzMb1qZ1iwy2bssvMr/bQXuRkmL06Lh3sdspnF/ulS5SrnLOdQkZRods6Xt2BsslZtbEzGoCPYHJZnZQpGxU6kCZk5MNQGpqapH5S3Nzi6bLjpwu1u1UNDuOOyXsuJfmFp+upPIrqXyXVuzyi0VWplczLCgoKDK/erUqNKhbk6zMegBsD1u+R+O6iclgnFkp/kUxDGgBbAPaA8cB/wFuBnKAPSOtXKn7KLdt21Ym6WLdTkWTr/KLuyppqX9peXlXVn2UzrlcYHDY7GeBS2JZv1LXKLOymgHgnCsyv2nYhYisZiWka5oVeXnYdiqaEsuvaYzllxWl/JpW7PKLReFFHguLGJs2b+XPtRvIWb7GWx5Wo8pdsTYxGYyzMro76C+Le6A0s+pmNsHM8szsuXjvrzS69+gJwObNm3eZP3/ePF6dMJ78/Hw6dupMenr6rul6euv36NFrl+2kp6fTsVPneGY/6XaU35ai5dKjZy/mz5vHK375dfLLb0tY+RWWW0nl16lzxS6/kjRvUp9zTziYGtWrkL18DUty/6Ba1SpF0nw5dxEFBY5psxcAUL1a0cbhF3MWJCy/cbMbV3PiJRE1yq54Vd7HgAvNLDCdJy1bteKUU0/f0Ye2ZvVqatasyQUXXsyxR/XhogvO5dlnniY9PZ3LBgwkNzcHgNWrV5Oamkq//gMBuPzKq0lLSyMnJxvnHOvWruWivpdQrVq1pB1bIrRs1YpTTjt9Rx/jar/8zr/wYo45sjcXnX8Oz44pLL9BJZbfFVddU0z5XVrhyw8gLc37FQztnx374KWMuetCbu5/HACPvfAR9WrXIL16VerXSQdg1CufAfDsxGmsXb9pR19lvTo1+N+n3/H7sogXccuNMuyj/Evi3kfpnPscwMxygdHOuUC1CUaMfpqrLh/I1VcOYuGCBbz9/kc0a96cww7vw8dTPuSgDh0BuOOue9m4cSP9+13CsqW5vPLa63Tp0hWADh078sLY8Ywa+SQTXh7HeRdcyL33l3zzcEUycvQYrrx8AFdfMYgFC37lnfen0Lx5cw7r3YePP9pZfnfefS+bNm6k/6V9Wbo0l1cnTqZL153l9+K4CYwaMZzx48Zy3gUXcd8DFb/8enTam36n9wAgo0Et+v+jF5OnzOHzmb+wX6tMvvrWu+1v5ITPaFivFiNuO5da6dUZcPtLTJ4yF4DclWs57eoR3HDpMRy0X3N++CWXq+4Zn7RjKktGcF6zZuH9QnHZiVln4C28Y+/od6yGLu8P9Ado3qJF559+XRz3PFVE4f1YErv6Xa9MdhbKtc1zhs90znUpy222O6iTe/Xdz6Mn9LVtWqvM81AoIRdznHMzgd5AHaBHMctHF9771KhR40RkSUTKgaA0vRNxMaebmVV3zs0HZgEV/y5iESkTZrEP8ZSI+yivB1qY2SjgPufcomgriIhAcF6zloiLOWfEex8iUkEFJFJW6idzRCS4vNsjgxEpFShFJJgS0PcYKwVKEQmsgMRJBUoRCbCAREoFShEJqPjfHxkrBUoRCSz1UYqIRJCI16fFSoFSRIIrIJFSgVJEAislIG1vBUoRCaxghEkFShEJKt1wLiISi2BESgVKEQmkIL3hXIFSRAIrIHFSgVJEgks1ShGRKPQIo4hINMGIkwqUIhJcAYmTCpQiEkyJ+GhYrBQoRSSw1EcpIhJNMOKkAqWIBFeKAqWISCR6w7mISERBeoQxJdkZEBEJOtUoRSSwglKjVKAUkcBSH6WISCS64VxEJDJ9hVFEJBYBiZQKlCISWOqjFBGJQn2UIiJRlFWcNLNmwDVAPeAq59xmM+sAnAY0Bi53zrmS1tcN5yISXFaKIbJBwAKgCnCeP+8G4AugDXBEpJUVKEUkkAxIMYt5iGI/IN//f5sI84oVuKb37FkzV6VXTVmS7HxE0AhYlexMlFMqu90X9LLbs6w3OGvWzPdqVLFGpVilupnNCJke7Zwb7f+/asj8lAjzihW4QOmca5zsPERiZjOcc12SnY/ySGW3+ypj2Tnnji3DzX3PzsC4xMyahM2bF2llNb1FpDIYBrQAtgHtgeOA+4CDgV+AjyKtHLgapYhIWXPO5QKDi1n0XSzrq0ZZeqOjJ5ESqOx2n8ouiSzCrUMiIoJqlCIiUSlQiohEoUAZIzOrluw8lEdmViPZeSivzKyePw7IE8+VlwJlDMzsBuBYM9NdAjEysxQzexZ43cz+4c/TL3wM/LJ7E/jGzI5xzjmVXXLpFz8KM2sOnIh3D9ZmM/vIOZcfZTWBocBRQB4w3swWOudmJjlP5cW/8V7eMB/4h5n97v9fV16TRDXK6Fbj3ZiaC4wBjlTNMiZTgNOBvwGP4T/iZmZ7JTNT5cSbwAnAEOBwYDpwv7p/kkeBMroNzrl38GpHi4Cnge5m1iC52Qq8GcC3zrkcYDZwgJm1AU41syrJzVrgLQTWAyvxgub9wBlAu2RmqjLTfZSl4AfHCXivZLoTuM85tzW5uQo+M6sKXA0cglfDbOWcW5vcXJUvZnYK8Kdz7rNk56UyUqAsJTPrAowCznPOzU92fsoDv6viVyAD6KW+ytj5f5xPB1oCDzjn1iU3R5WTmt6ltwg4UkGy1N4DuipIllot4GzgJQXJ5FGNUhLCzKo457YlOx/lkZlVc85tSXY+KjMFShGRKNT0FhGJQoFSRCQKBUoRkSgUKMsRMzvQzMaZmfOHUWb2g5lNNbMTy3A/+5jZF/4+bvfntTGzFWb2ZCm2U+pvvJjZ4Wa2yt9372KWH2Rmy0taHpY2zcwe8dN+Usp8pJnZsN1ZVyoeBcpyxDn3Hd5jlIXTA/Bu4O4ITDSzbmW0n1+AD8JmZ+J9KL5tLNswsxOAK3Zj358CP0RYPhfvuedYtpUPvFHaPISs+9rurCsVjwJl+bM9dMI5twz4Ee8FJ/8ow/0UuR3COfcJ3iN0J0Vb0cw6As8Ry2fpY9j3biwvK7olRAAFyoqiuj/eaGZ7mdl8v8nY1296rjazIwDMrLeZjTWz+8zsXf/tSJhZVTMbbmbZZvZfoFPhxv1lw/A+7/lGyPyuZvaOmT3j7/MY/zOgI4CGwFH+Ptr76a/w9/GCmY30H23EzJqa2Xtm9qOZPQ/UL83B+90Cw83sTjP73cxeMrP0sGS1zOwJ//i+NrN2IevvaWbjzWyImX1mZoeXZv9SCTjnNJSjAeiNV9Nx/nR3oABYBbTw5z3vp/kMuBlYAfQB9ge2AMf76eYA7/r//7e/ziX+9Jv+9O3+dB9/+hN/uj7wJ3A3UAXYBPziL7vYT/tcSL4vwasN18F7hZgDBvvLpvjTe/nLsv3p3iWUwSehy4EFwFT///f7yy4PK6+fgdpAB3/6F7yKQjV/2VA//WN+WdYMWfeTZP/cNSR30OvCyjG/ltcceAAY4Zz7zV9U2GT81jl3L3Cvn/4JvA++H29mB+IFi8I3+Vzgj2f445l4r/oqFN4MvQgvWC5xzm0zs/PxAnZJ/ukvv8Lf1kdADTPLwgvCq51zC/18/gpkRS+BHb4CqphZCl5NFqBRWJpc59x6YI6ZrQFaAwcCewP7AAea2WAgHe8PSJNS7F8qOAXKcsw5d2WUJPPCplv740+dcxPClrXwx5tj3P2+/jjDz0u0Cx+t8c63Z5xzy/FqfpjZoaXc7y6cc+ea2enAf/E+cA+Ru5Xy8GqutdhZJoucc/eHJirslhBRH2XFtiFseqU/7lM4w8wKA+QKfxzrezZz/XFxtyUVdxGkpH0X7rfe7n7uwK8pv4RXWw3/41CcdLxugJ9C8nV44f7NLN3MGpa0slQ+CpTlT2rhf/ymZnFKmv+yP77YzM43s854r/ACeNUfH29m1fFuOwKvXw92XsEuHL+E1995iJkNNbPOZnaj/1LePD9NDTPL8oNO4b7vN7Ne/n2fHZ1zC4BZQA3gCDNrCRwQtu9wO/Ji3ge4rsIrl0OAg/1laWEXdBr7KzTB+2PwonNuFd7FqQ1AGz9vbYCbgHXFHLNUVsnuJNUQ+4DXpzYO/2IOcC2QFZamBV6tyvlpG4Utvw6vNpiHd9Gnhj+/Fl7TdQPwFvAEXgAbjvcZh5H+NpcDnfx1jgTm+ut8DOzvz6+J1we5Drjbn1cDeMaftwK4ISRP+wPf4F0cehJ4G/gU7wJT1bD8H+LnwQH/wbsY876/3SeBU4C1wOdAU7wLMq/iNfWfBN4BhgHVQ7Z5NN4tVpvxLoDthddN8LS/n2VAh2T//DUkb9Dbg0REolDTW0QkCgVKEZEoFChFRKJQoBQRiUKBUkQkCgVKEZEoFChFRKJQoBQRiUKBUkQkiv8HCIvRylRXVbsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('#'*20)\n",
    "print('train-混淆矩阵')\n",
    "cm = confusion_matrix(y_train, np.argmax(train_pred, 1))\n",
    "plot_confusion_matrix(cm, classes=['1','2','3'], normalize=True, title='Normalized confusion matrix')\n",
    "\n",
    "print('#'*20)\n",
    "print('test-混淆矩阵')\n",
    "cm = confusion_matrix(y_test, np.argmax(test_pred, 1))\n",
    "plot_confusion_matrix(cm, classes=['1','2','3'], normalize=True, title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['pred_stage2'] = np.argmax(train_pred, 1)+1\n",
    "test['pred_stage2'] = np.argmax(test_pred, 1)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "valid_pred = np.argmax(preds_valid, 1)\n",
    "valid['pred_stage2'] = valid_pred+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_output = features_slc + ['label2','pred_stage2']\n",
    "train[cols_output].to_excel('../res_stage2/train.xlsx', index=False)\n",
    "test[cols_output].to_excel('../res_stage2/test.xlsx', index=False)\n",
    "\n",
    "valid[[f for f in cols_output if f not in ['label2']]].to_excel('../res_stage2/valid.xlsx', index=False)\n",
    "\n",
    "df_feature_importance.sort_values(by='gain', ascending=False).to_excel('../res/feature importance.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "feature importance：\n",
      "     features   gain\n",
      "8       ER/TM  240.8\n",
      "3       TM/YB  230.8\n",
      "1       YB/LU  223.6\n",
      "6        TH/U  198.8\n",
      "0   CE**EU*EU  195.2\n",
      "35  TI/NB/EU*  193.8\n",
      "5       ER/YB  191.6\n",
      "4     Y/LA/TB  175.2\n",
      "31   YB/LU/HF  175.0\n",
      "17   Y/CE*/TH  174.4\n"
     ]
    }
   ],
   "source": [
    "print('#'*20)\n",
    "print('feature importance：')\n",
    "print(df_feature_importance.sort_values(by='gain', ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
